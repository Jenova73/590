{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f50ODjhO9CSZ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W7e0w-139Iij"
   },
   "source": [
    "### 1. Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSsmLzjE9s-a"
   },
   "source": [
    "\n",
    "Let's start by writing some functions for activation functions that we would like to be able to use.\n",
    "\n",
    "Fill in the functions below to implement the associated activation functions. Any time you need a special function (e.g. exponentation), try to find a version in NumPy so that your activation functions will work on single values as well as arrays.\n",
    "\n",
    "*bonus*: try to implment the ReLU activation function so that it works elementwise on a NumPy -- this is called \"vectorizing\" your code. Hint: check out the `np.where` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yr4mkpLh9yGP"
   },
   "outputs": [],
   "source": [
    "def linear(z):\n",
    "    return z\n",
    "\n",
    "# more specifically, the logistic sigmoid that has values between 0 and 1\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-np.array(z)))\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(np.array(z))\n",
    "\n",
    "def relu(z):\n",
    "    return max(0,np.array(z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-VEZ_W1V7yUv"
   },
   "outputs": [],
   "source": [
    "a = np.array([-1.0, 0.0, 1.0])\n",
    "\n",
    "np.testing.assert_equal(linear(5), 5)\n",
    "np.testing.assert_equal(linear(-3.0), -3.0)\n",
    "np.testing.assert_array_equal(linear(a), a)\n",
    "\n",
    "np.testing.assert_equal(sigmoid(0.0), 0.5)\n",
    "np.testing.assert_allclose(sigmoid(a), [0.26894142, 0.5, 0.73105858])\n",
    "\n",
    "np.testing.assert_equal(tanh(0.0), 0.0)\n",
    "np.testing.assert_allclose(tanh(a), [-0.76159416, 0.0, 0.76159416])\n",
    "\n",
    "np.testing.assert_equal(relu(5), 5)\n",
    "np.testing.assert_equal(relu(-5), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3R7FZ8y9S1v"
   },
   "source": [
    "### 2. Try it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edvxHceU_XkJ"
   },
   "source": [
    "Let's reuse our neural net layer function from last time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IbMrGPe9_X2d"
   },
   "outputs": [],
   "source": [
    "def nn_layer(X, W, b, f):\n",
    "  return f(np.dot(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XLIsi2EuAkut"
   },
   "outputs": [],
   "source": [
    "def nn_two_layers(X, W_1, b_1, f_1, W_2, b_2, f_2):\n",
    "  H = nn_layer(X, W_1, b_1, f_1)\n",
    "  Y_hat = nn_layer(H, W_2, b_2, f_2)\n",
    "  return Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sf7oiWBp_jbE"
   },
   "source": [
    "But now, we have multiple activation functions to try out. As we did previously, create randomized weight matrices for a network with scalar input, scalar output and any number of hidden nodes in a single layer. Generate plots of this input output relationships.\n",
    "\n",
    "This time, try out different activation functions: linear, sigmoid, tanh, relu and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Er92ByXX_egf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the input dimension, the number of hidden units, and the number of ouptput units\n",
    "n_input, n_hidden, n_output = 1, 15, 1\n",
    "\n",
    "# We want get the NN's output for a range of input values, so that we cant plot\n",
    "# input vs output. We can get evenly space values using `np.linspace`. We also\n",
    "# want to process these inputs as a \"batch\", so we use `np.newaxis` to turn this\n",
    "# 1-d array into a 2-d array with a single column.\n",
    "n_grid = 100\n",
    "X = np.linspace(-10, 10, n_grid)[:, np.newaxis]\n",
    "\n",
    "# We can generate random values (drawn from a standard gaussian distribution --\n",
    "# mean = 0, standard deviation = 1), with `np.random.randn(shape)`\n",
    "W_1 = np.random.randn(n_input, n_hidden)\n",
    "b_1 = np.random.randn(n_hidden)\n",
    "W_2 = np.random.randn(n_hidden, n_output)\n",
    "b_2 = np.random.randn(n_output)\n",
    "Y_hat = nn_two_layers(X,W_1,b_1,tanh, W_2, b_2, tanh)\n",
    "plt.plot(X,Y_hat)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LBI23a_F9Xuu"
   },
   "source": [
    "### 3.  Outputs and Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kgPrHIxbBEVy"
   },
   "source": [
    "Next, we'll define some common Output activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dQxHU6t3PraV"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return  1/(1 + np.exp(-z))\n",
    "\n",
    "def softmax(z):\n",
    "    e_z = np.exp(z)\n",
    "    return e_z / e_z.sum(axis=1)[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AAFko6cqRFP6"
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(\n",
    "    sigmoid(2),\n",
    "    np.array([.88]),\n",
    "    decimal=2\n",
    ")\n",
    "\n",
    "np.testing.assert_almost_equal(\n",
    "    sigmoid(np.array([2,-2,1,-1])),\n",
    "    np.array([.88, .12, .73, .27]),\n",
    "    decimal=2\n",
    ")\n",
    "\n",
    "np.testing.assert_almost_equal(\n",
    "    softmax(np.array([[2,5,1], [3,1,1]])),\n",
    "    np.array([[0.046, 0.93, 0.017],\n",
    "       [0.78, 0.10, 0.10]]),\n",
    "    decimal=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNrgYJtqBKyw"
   },
   "source": [
    "Next, we'll define some common Loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMvoYMgSBNiD"
   },
   "outputs": [],
   "source": [
    "def squared_error(y_hat, y_true):\n",
    "\n",
    "    return(y_hat-y_true)**2\n",
    "\n",
    "\n",
    "def binary_crossentropy(y_hat, y_true):\n",
    "\n",
    "    return -y_true*np.log(y_hat)-(1-y_true)*np.log(1-y_hat)\n",
    "\n",
    "\n",
    "def binary_crossentropy_onehot(y_hat, y_true):\n",
    "\n",
    "    return -(y_true *np.log(y_hat)).sum(axis=1)\n",
    "\n",
    "\n",
    "def categorical_crossentropy(y_hat, y_true):\n",
    "\n",
    "\n",
    "    return -(y_true *np.log(y_hat)).sum(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LgAP3aFeEWOX"
   },
   "outputs": [],
   "source": [
    "np.testing.assert_equal(\n",
    "    squared_error(np.array([1,2,4]), np.array([5,4,3])),\n",
    "    np.array([16, 4, 1])\n",
    ")\n",
    "\n",
    "\n",
    "np.testing.assert_almost_equal(\n",
    "    binary_crossentropy(\n",
    "        np.array([.51, .49, .99, 0.01, .99 ]), \n",
    "        np.array([1, 1, 1, 1, 0])),\n",
    "    np.array([0.67, 0.71, 0.01, 4.60, 4.60]),\n",
    "    decimal=2\n",
    ")\n",
    "\n",
    "np.testing.assert_almost_equal(\n",
    "    binary_crossentropy_onehot(\n",
    "        np.array([[.49, .51], [.51, .49], [.01, .99], [0.99, .01], [.01, .99] ]), \n",
    "        np.array([[0, 1], [0, 1], [0, 1], [0, 1], [1, 0]])),\n",
    "    np.array([0.67, 0.71, 0.01, 4.60, 4.60]),\n",
    "    decimal=2\n",
    ")\n",
    "\n",
    "np.testing.assert_almost_equal(\n",
    "      categorical_crossentropy(\n",
    "        np.array([[.4, .5, .1], [.2, .2, .6]  ]), \n",
    "        np.array([[0, 1, 0], [0, 1, 0],])),\n",
    "    np.array([0.69, 1.6]),\n",
    "    decimal=2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8FZ8gj-9dkd"
   },
   "source": [
    "###4. Discussion problem with your groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cCdSFuKmTk7v"
   },
   "source": [
    "Suppose we want to predict if a person is a credit risk (Yes or No) based on their {Income, Age, YearsOfEducation}. Draw a diagram of a possible neural network (with one hidden layer) to fit a datset like this. \n",
    "* How many input nodes and output nodes are there?\n",
    "\n",
    "3 input: income, age, year of education. 1 output: yes/no\n",
    "\n",
    "* Pick how many nodes are in the hidden layer. Pick an activation function in the hidden layer. Include bias nodes at the hidden layer and the output layer.\n",
    "\n",
    "3 bides in the hidden layer with linear function.\n",
    "\n",
    "* What activation function would you pick for the output layer?\n",
    "\n",
    "sigmoid function \n",
    "\n",
    "* What loss function would you pick for fitting this model?\n",
    "\n",
    "binary Cross Entropy\n",
    "\n",
    "* How many total free parameters are in this network? \n",
    "\n",
    "14\n",
    "3 w1_\n",
    "3 w2_\n",
    "3 w3_\n",
    "3 w\n",
    "2 b_\n",
    "\n",
    "* Write an equation for the output of this network as a function of its input.\n",
    "\n",
    "h1 = x1w11 + x2w12 + x3w13 +b1\n",
    "h2 = x1w21 + x2w22 + x3w23 +b1\n",
    "h3 = x1w31 + x2w32 + x3w33 +b1\n",
    "result = h1w1 + h2w2 + h3w3+ b2"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab2-ffnn-part2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
